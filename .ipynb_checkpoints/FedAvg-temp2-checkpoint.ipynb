{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a18e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "from opacus import PrivacyEngine\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "import importlib\n",
    "importlib.import_module('FLDataset')\n",
    "from FLDataset import load_dataset, getActualImgs, CovidDataset, Rescale, ToTensor\n",
    "from utils import averageModels, averageGradients\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e4b0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 3012\n",
    "        self.clients = 50\n",
    "        self.rounds = 1001\n",
    "        self.epochs = 1\n",
    "        self.local_batches = 20\n",
    "        self.lr = 0.01\n",
    "        self.dropout1 = 0.25\n",
    "        self.dropout2 = 0.5\n",
    "        self.C = 0.66\n",
    "        self.drop_rate = 0.1\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'noniid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = True\n",
    "        self.save_model = False\n",
    "        self.save_model_interval = 500\n",
    "        self.clip = 1\n",
    "        self.del_runs = False\n",
    "        self.acc_csv = True\n",
    "        self.acc_file = '0517_50clients_noniid1.csv'\n",
    "        # number of classes per client on non iid case \n",
    "        self.noniid_classnum = 1\n",
    "        # data transform\n",
    "        self.transform = transforms.Compose([Rescale(32), ToTensor()])\n",
    "        # number of classes\n",
    "        self.c_num = 3\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a83cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete files in runs (Tensorboard)\n",
    "if args.del_runs==True:\n",
    "    folder = 'runs'\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f697766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create accuracy csv file\n",
    "def acc_csv(args, rnd, acc):\n",
    "    if args.acc_csv==True:\n",
    "        with open(\"acc_csv_files/\"+args.acc_file, 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([rnd, acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b48621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hook': <VirtualWorker id:client1 #objects:0>}, {'hook': <VirtualWorker id:client2 #objects:0>}, {'hook': <VirtualWorker id:client3 #objects:0>}, {'hook': <VirtualWorker id:client4 #objects:0>}, {'hook': <VirtualWorker id:client5 #objects:0>}, {'hook': <VirtualWorker id:client6 #objects:0>}, {'hook': <VirtualWorker id:client7 #objects:0>}, {'hook': <VirtualWorker id:client8 #objects:0>}, {'hook': <VirtualWorker id:client9 #objects:0>}, {'hook': <VirtualWorker id:client10 #objects:0>}, {'hook': <VirtualWorker id:client11 #objects:0>}, {'hook': <VirtualWorker id:client12 #objects:0>}, {'hook': <VirtualWorker id:client13 #objects:0>}, {'hook': <VirtualWorker id:client14 #objects:0>}, {'hook': <VirtualWorker id:client15 #objects:0>}, {'hook': <VirtualWorker id:client16 #objects:0>}, {'hook': <VirtualWorker id:client17 #objects:0>}, {'hook': <VirtualWorker id:client18 #objects:0>}, {'hook': <VirtualWorker id:client19 #objects:0>}, {'hook': <VirtualWorker id:client20 #objects:0>}, {'hook': <VirtualWorker id:client21 #objects:0>}, {'hook': <VirtualWorker id:client22 #objects:0>}, {'hook': <VirtualWorker id:client23 #objects:0>}, {'hook': <VirtualWorker id:client24 #objects:0>}, {'hook': <VirtualWorker id:client25 #objects:0>}, {'hook': <VirtualWorker id:client26 #objects:0>}, {'hook': <VirtualWorker id:client27 #objects:0>}, {'hook': <VirtualWorker id:client28 #objects:0>}, {'hook': <VirtualWorker id:client29 #objects:0>}, {'hook': <VirtualWorker id:client30 #objects:0>}, {'hook': <VirtualWorker id:client31 #objects:0>}, {'hook': <VirtualWorker id:client32 #objects:0>}, {'hook': <VirtualWorker id:client33 #objects:0>}, {'hook': <VirtualWorker id:client34 #objects:0>}, {'hook': <VirtualWorker id:client35 #objects:0>}, {'hook': <VirtualWorker id:client36 #objects:0>}, {'hook': <VirtualWorker id:client37 #objects:0>}, {'hook': <VirtualWorker id:client38 #objects:0>}, {'hook': <VirtualWorker id:client39 #objects:0>}, {'hook': <VirtualWorker id:client40 #objects:0>}, {'hook': <VirtualWorker id:client41 #objects:0>}, {'hook': <VirtualWorker id:client42 #objects:0>}, {'hook': <VirtualWorker id:client43 #objects:0>}, {'hook': <VirtualWorker id:client44 #objects:0>}, {'hook': <VirtualWorker id:client45 #objects:0>}, {'hook': <VirtualWorker id:client46 #objects:0>}, {'hook': <VirtualWorker id:client47 #objects:0>}, {'hook': <VirtualWorker id:client48 #objects:0>}, {'hook': <VirtualWorker id:client49 #objects:0>}, {'hook': <VirtualWorker id:client50 #objects:0>}]\n",
      "number of clients :  50\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "clients = []\n",
    "\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})\n",
    "\n",
    "print(clients)\n",
    "print(\"number of clients : \", len(clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590f3e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "(0, 2)\n",
      "(1, 2)\n",
      "comb  [(0, 1), (0, 2), (1, 2)]\n",
      "client_classes  [[0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]]\n",
      "label count  Counter({0: 34, 1: 33, 2: 33})\n",
      "users_dict  {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 11: [], 12: [], 13: [], 14: [], 15: [], 16: [], 17: [], 18: [], 19: [], 20: [], 21: [], 22: [], 23: [], 24: [], 25: [], 26: [], 27: [], 28: [], 29: [], 30: [], 31: [], 32: [], 33: [], 34: [], 35: [], 36: [], 37: [], 38: [], 39: [], 40: [], 41: [], 42: [], 43: [], 44: [], 45: [], 46: [], 47: [], 48: [], 49: []}\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "(1, 2)\n",
      "comb  [(0, 1), (0, 2), (1, 2)]\n",
      "client_classes  [[0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]\n",
      " [1 2]\n",
      " [0 1]\n",
      " [0 2]]\n",
      "label count  Counter({0: 34, 1: 33, 2: 33})\n",
      "users_dict  {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 11: [], 12: [], 13: [], 14: [], 15: [], 16: [], 17: [], 18: [], 19: [], 20: [], 21: [], 22: [], 23: [], 24: [], 25: [], 26: [], 27: [], 28: [], 29: [], 30: [], 31: [], 32: [], 33: [], 34: [], 35: [], 36: [], 37: [], 38: [], 39: [], 40: [], 41: [], 42: [], 43: [], 44: [], 45: [], 46: [], 47: [], 48: [], 49: []}\n"
     ]
    }
   ],
   "source": [
    "global_train, global_test, train_group, test_group = load_dataset(args.clients, \\\n",
    "                                                                  args.iid, \\\n",
    "                                                                  args.transform, \\\n",
    "                                                                  args.c_num, \\\n",
    "                                                                  args.noniid_classnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d35d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3012\n",
      "<class 'FLDataset.CovidDataset'>\n",
      "753\n",
      "<class 'FLDataset.CovidDataset'>\n",
      "50\n",
      "<class 'dict'>\n",
      "50\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(len(global_train))\n",
    "print(type(global_train))\n",
    "print(len(global_test))\n",
    "print(type(global_test))\n",
    "print(len(train_group))\n",
    "print(type(train_group))\n",
    "print(len(test_group))\n",
    "print(type(test_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdab2028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(client 0 train set) =  59\n",
      "len(client 1 train set) =  59\n",
      "len(client 2 train set) =  60\n",
      "len(client 3 train set) =  59\n",
      "len(client 4 train set) =  59\n",
      "len(client 5 train set) =  60\n",
      "len(client 6 train set) =  59\n",
      "len(client 7 train set) =  59\n",
      "len(client 8 train set) =  60\n",
      "len(client 9 train set) =  59\n",
      "len(client 10 train set) =  59\n",
      "len(client 11 train set) =  60\n",
      "len(client 12 train set) =  59\n",
      "len(client 13 train set) =  59\n",
      "len(client 14 train set) =  60\n",
      "len(client 15 train set) =  59\n",
      "len(client 16 train set) =  59\n",
      "len(client 17 train set) =  60\n",
      "len(client 18 train set) =  59\n",
      "len(client 19 train set) =  59\n",
      "len(client 20 train set) =  60\n",
      "len(client 21 train set) =  59\n",
      "len(client 22 train set) =  59\n",
      "len(client 23 train set) =  60\n",
      "len(client 24 train set) =  60\n",
      "len(client 25 train set) =  60\n",
      "len(client 26 train set) =  60\n",
      "len(client 27 train set) =  60\n",
      "len(client 28 train set) =  60\n",
      "len(client 29 train set) =  62\n",
      "len(client 30 train set) =  61\n",
      "len(client 31 train set) =  61\n",
      "len(client 32 train set) =  62\n",
      "len(client 33 train set) =  61\n",
      "len(client 34 train set) =  61\n",
      "len(client 35 train set) =  62\n",
      "len(client 36 train set) =  61\n",
      "len(client 37 train set) =  61\n",
      "len(client 38 train set) =  62\n",
      "len(client 39 train set) =  61\n",
      "len(client 40 train set) =  61\n",
      "len(client 41 train set) =  62\n",
      "len(client 42 train set) =  61\n",
      "len(client 43 train set) =  61\n",
      "len(client 44 train set) =  62\n",
      "len(client 45 train set) =  61\n",
      "len(client 46 train set) =  61\n",
      "len(client 47 train set) =  62\n",
      "len(client 48 train set) =  61\n",
      "len(client 49 train set) =  61\n"
     ]
    }
   ],
   "source": [
    "for inx, client in enumerate(clients):\n",
    "    trainset_ind_list = list(train_group[inx])\n",
    "    print(\"len(client\", str(inx), \"train set) = \", len(trainset_ind_list))\n",
    "    client['trainset'] = getActualImgs(global_train, trainset_ind_list, args.local_batches)\n",
    "    client['testset'] = getActualImgs(global_test, list(test_group[inx]), args.local_batches)\n",
    "    client['samples'] = len(trainset_ind_list) / args.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42a94faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "global_test_dataset = CovidDataset('./test.csv', transform=transforms.Compose([Rescale(32), ToTensor()]))\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True, drop_last=True)\n",
    "print(len(global_test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dcd07f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = 32,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32,\n",
    "                               out_channels = 64,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "        self.fc1 = nn.Linear(14*14*64, 128)\n",
    "#         self.fc1_bn = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.conv1_bn(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, p=args.dropout1)\n",
    "        x = x.view(-1, 14*14*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=args.dropout2)\n",
    "#         x = self.fc1_bn(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff2e6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientUpdate(args, device, client):\n",
    "    client['model'].train()\n",
    "#     client['model'].send(client['hook'])\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        for batch_idx, (data, target) in enumerate(client['trainset']):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            client['optim'].zero_grad()\n",
    "#             output = client['model'](data.float())\n",
    "#             loss = F.nll_loss(output, target.squeeze(1))\n",
    "            output = client['model'](data)\n",
    "            loss = client['criterion'](output, target.squeeze(1))\n",
    "            loss.backward()\n",
    "            \n",
    "#             print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "#             print(\"output: \", output)\n",
    "#             print(\"target squeeze: \", target.squeeze(1))\n",
    "#             print(\"loss: \", loss)\n",
    "#             print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "            \n",
    "#             print weight \n",
    "#             for name, param in client['model'].named_parameters():\n",
    "#                 if name=='conv1_bn.weight':\n",
    "#                     print(name, param.grad)\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(client['model'].parameters(), args.clip)\n",
    "            client['optim'].step()\n",
    "            \n",
    "            \n",
    "            if batch_idx % args.log_interval == 0 or batch_idx==len(client['trainset'])-1:\n",
    "#                 loss = loss.get() \n",
    "                print('Model [{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    client['hook'].id,\n",
    "                    epoch, (batch_idx+1) * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                    100. * (batch_idx+1) / len(client['trainset']), loss.item()/args.log_interval))\n",
    "                \n",
    "#     client['model'].get() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0467f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for d in test_loader:\n",
    "            data = d['image']\n",
    "            target = d['label']\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if(str(device)=='cuda'):\n",
    "                model.cuda()\n",
    "            output = model(data.float())\n",
    "#             test_loss += F.nll_loss(output, target.squeeze(1), reduction='sum').item() # sum up batch loss\n",
    "            loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target.squeeze(1)).item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a9677cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bc938d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             320\n",
      "       BatchNorm2d-2           [-1, 32, 30, 30]              64\n",
      "            Conv2d-3           [-1, 64, 28, 28]          18,496\n",
      "            Linear-4                  [-1, 128]       1,605,760\n",
      "            Linear-5                    [-1, 3]             387\n",
      "================================================================\n",
      "Total params: 1,625,027\n",
      "Trainable params: 1,625,027\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.82\n",
      "Params size (MB): 6.20\n",
      "Estimated Total Size (MB): 7.03\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py:414: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  response = command_method(*args_, **kwargs_)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.torch_seed)\n",
    "global_model = Net().to(device)\n",
    "summary(global_model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129a623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================================\n",
      "[round] =  1 / 1001\n",
      "===================================================================\n",
      "* [client count] =  1 / 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:560: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model [client29] Train Epoch: 1 [20/60 (33%)]\tLoss: 0.111676\n",
      "Model [client29] Train Epoch: 1 [60/60 (100%)]\tLoss: 0.106532\n",
      "* [client_train_time] =  0:00:01\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 33\n",
      "Model [client12] Train Epoch: 1 [20/60 (33%)]\tLoss: 0.111631\n",
      "Model [client12] Train Epoch: 1 [60/60 (100%)]\tLoss: 0.108577\n",
      "* [client_train_time] =  0:00:01\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  3 / 33\n",
      "Model [client11] Train Epoch: 1 [20/60 (33%)]\tLoss: 0.108831\n",
      "Model [client11] Train Epoch: 1 [60/60 (100%)]\tLoss: 0.107410\n",
      "* [client_train_time] =  0:00:01\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  4 / 33\n",
      "Model [client42] Train Epoch: 1 [20/80 (25%)]\tLoss: 0.112829\n",
      "Model [client42] Train Epoch: 1 [80/80 (100%)]\tLoss: 0.108563\n",
      "* [client_train_time] =  0:00:01\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  5 / 33\n",
      "Model [client3] Train Epoch: 1 [20/60 (33%)]\tLoss: 0.113133\n",
      "Model [client3] Train Epoch: 1 [60/60 (100%)]\tLoss: 0.108621\n",
      "* [client_train_time] =  0:00:01\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  6 / 33\n",
      "Model [client28] Train Epoch: 1 [20/60 (33%)]\tLoss: 0.108914\n",
      "Model [client28] Train Epoch: 1 [60/60 (100%)]\tLoss: 0.103488\n",
      "* [client_train_time] =  0:00:01\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  7 / 33\n",
      "Model [client39] Train Epoch: 1 [20/80 (25%)]\tLoss: 0.111973\n",
      "Model [client39] Train Epoch: 1 [80/80 (100%)]\tLoss: 0.105874\n",
      "* [client_train_time] =  0:00:01\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  8 / 33\n",
      "Model [client32] Train Epoch: 1 [20/80 (25%)]\tLoss: 0.110548\n",
      "Model [client32] Train Epoch: 1 [80/80 (100%)]\tLoss: 0.092771\n",
      "* [client_train_time] =  0:00:01\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  9 / 33\n",
      "Model [client23] Train Epoch: 1 [20/60 (33%)]\tLoss: 0.111275\n",
      "Model [client23] Train Epoch: 1 [60/60 (100%)]\tLoss: 0.106424\n",
      "* [client_train_time] =  0:00:01\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  10 / 33\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for client in clients:\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr, momentum = 0.8)\n",
    "    client['criterion'] = nn.CrossEntropyLoss(reduction='mean')\n",
    "#     client['pengine'] = PrivacyEngine(\n",
    "#                                        client['model'],\n",
    "#                                        batch_size=args.local_batches,\n",
    "#                                        sample_size=len(client['trainset']),\n",
    "#                                        alphas=range(2,32),\n",
    "#                                        noise_multiplier=0,\n",
    "#                                        max_grad_norm=1000\n",
    "#                                     )\n",
    "#     client['pengine'].attach(client['optim']) \n",
    "    \n",
    "# start training model\n",
    "training_start_time = time.time()\n",
    "for fed_round in range(args.rounds):\n",
    "    print(\"\")\n",
    "    print(\"===================================================================\")\n",
    "    print(\"[round] = \", fed_round+1, \"/\", args.rounds)\n",
    "    print(\"===================================================================\")\n",
    "    \n",
    "    round_train_start_time = time.time()\n",
    "    \n",
    "#     uncomment if you want a randome fraction for C every round\n",
    "#     args.C = float(format(np.random.random(), '.1f'))    \n",
    "    \n",
    "    # number of selected clients\n",
    "    m = int(max(math.ceil(args.C * args.clients), 1))\n",
    "\n",
    "    # Selected devices\n",
    "    np.random.seed(fed_round)\n",
    "    selected_clients_inds = np.random.choice(range(len(clients)), m, replace=False)\n",
    "    selected_clients = [clients[i] for i in selected_clients_inds]\n",
    "    \n",
    "    # Active devices\n",
    "#     np.random.seed(fed_round)\n",
    "#     active_clients_inds = np.random.choice(selected_clients_inds, int((1-args.drop_rate) * m), replace=False)\n",
    "#     active_clients = [clients[i] for i in active_clients_inds]\n",
    "    active_clients = selected_clients\n",
    "    \n",
    "    # Training \n",
    "    client_cnt = 0\n",
    "    for client in active_clients:\n",
    "        print(\"* [client count] = \", client_cnt+1 , \"/\", len(active_clients))\n",
    "        client_train_start_time = time.time()\n",
    "        ClientUpdate(args, device, client)\n",
    "        client_cnt += 1\n",
    "        client_train_time = round(time.time()-client_train_start_time)\n",
    "        print(\"* [client_train_time] = \", str(timedelta(seconds=(client_train_time))))\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "    \n",
    "#         # Testing \n",
    "#         for client in active_clients:\n",
    "#             test(args, client['model'], device, client['testset'], client['hook'].id)\n",
    "    \n",
    "    # Averaging \n",
    "#     print(\"active clients: \", active_clients)\n",
    "    global_model = averageModels(global_model, active_clients)\n",
    "    \n",
    "    # Testing the average model\n",
    "    acc = test(args, global_model, device, global_test_loader, 'Global')\n",
    "    writer.add_scalar(\"Accuracy/train\", acc, fed_round)\n",
    "    writer.flush()\n",
    "    acc_csv(args, fed_round, acc)\n",
    "            \n",
    "    # Share the global model with the clients\n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(global_model.state_dict())\n",
    "        \n",
    "    # training time per round\n",
    "    total_train_time = round(time.time()-training_start_time)\n",
    "    round_train_time = round(time.time()-round_train_start_time)\n",
    "    print(\"** [total train time]: \", str(timedelta(seconds=total_train_time)))\n",
    "    print(\"** [round train time]: \", str(timedelta(seconds=round_train_time)))\n",
    "    \n",
    "    if (args.save_model and fed_round%args.save_model_interval==0 and fed_round!=0):\n",
    "        now = datetime.now() \n",
    "        date = now.strftime(\"%Y_%m_%d_%H%M\")\n",
    "        torch.save(global_model.state_dict(), date + \"_FedAvg_with_DP_round_\" + str(fed_round) + \".pth\")\n",
    "        print(\"model saved : \"+ date +\"_FedAvg_with_DP_round_\" + str(fed_round) + \"10clients.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard open \n",
    "# tensorboard --logdir=/home/citi302/Desktop/Codefolder/FL_DP_covid/runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
