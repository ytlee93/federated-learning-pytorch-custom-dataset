{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a3cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "from opacus import PrivacyEngine\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "import importlib\n",
    "importlib.import_module('FLDataset')\n",
    "from FLDataset import load_dataset, getActualImgs, CovidDataset, Rescale, ToTensor\n",
    "from utils import averageModels, averageGradients\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5102a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 3012\n",
    "        self.clients = 10\n",
    "        self.rounds = 1000\n",
    "        self.epochs = 1\n",
    "        self.local_batches = 16\n",
    "        self.lr = 0.02\n",
    "        self.dropout = 0.5\n",
    "        self.C = 0.9\n",
    "        self.drop_rate = 0.1\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = True\n",
    "        self.save_model = True\n",
    "        self.save_model_interval = 200\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864e37bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hook': <VirtualWorker id:client1 #objects:0>}, {'hook': <VirtualWorker id:client2 #objects:0>}, {'hook': <VirtualWorker id:client3 #objects:0>}, {'hook': <VirtualWorker id:client4 #objects:0>}, {'hook': <VirtualWorker id:client5 #objects:0>}, {'hook': <VirtualWorker id:client6 #objects:0>}, {'hook': <VirtualWorker id:client7 #objects:0>}, {'hook': <VirtualWorker id:client8 #objects:0>}, {'hook': <VirtualWorker id:client9 #objects:0>}, {'hook': <VirtualWorker id:client10 #objects:0>}]\n",
      "number of clients :  10\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "clients = []\n",
    "\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})\n",
    "\n",
    "print(clients)\n",
    "print(\"number of clients : \", len(clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cdd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train, global_test, train_group, test_group = load_dataset(args.clients, args.iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1373907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3012\n",
      "<class 'FLDataset.CovidDataset'>\n",
      "753\n",
      "<class 'FLDataset.CovidDataset'>\n",
      "10\n",
      "<class 'dict'>\n",
      "10\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(len(global_train))\n",
    "print(type(global_train))\n",
    "print(len(global_test))\n",
    "print(type(global_test))\n",
    "print(len(train_group))\n",
    "print(type(train_group))\n",
    "print(len(test_group))\n",
    "print(type(test_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0304a8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(client 0 train set) =  301\n",
      "len(client 1 train set) =  301\n",
      "len(client 2 train set) =  301\n",
      "len(client 3 train set) =  301\n",
      "len(client 4 train set) =  301\n",
      "len(client 5 train set) =  301\n",
      "len(client 6 train set) =  301\n",
      "len(client 7 train set) =  301\n",
      "len(client 8 train set) =  301\n",
      "len(client 9 train set) =  301\n"
     ]
    }
   ],
   "source": [
    "for inx, client in enumerate(clients):\n",
    "    trainset_ind_list = list(train_group[inx])\n",
    "    print(\"len(client\", str(inx), \"train set) = \", len(trainset_ind_list))\n",
    "    client['trainset'] = getActualImgs(global_train, trainset_ind_list, args.local_batches)\n",
    "    client['testset'] = getActualImgs(global_test, list(test_group[inx]), args.local_batches)\n",
    "    client['samples'] = len(trainset_ind_list) / args.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb2547eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "global_test_dataset = CovidDataset('./test.csv', transform=transforms.Compose([Rescale(64), ToTensor()]))\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220a0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(30*30*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 30*30*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=args.dropout)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b640b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientUpdate(args, device, client):\n",
    "    client['model'].train()\n",
    "#     client['model'].send(client['hook'])\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        for batch_idx, (data, target) in enumerate(client['trainset']):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            client['optim'].zero_grad()\n",
    "            output = client['model'](data.float())\n",
    "            loss = F.nll_loss(output, target.squeeze(1))\n",
    "            loss.backward()\n",
    "            client['optim'].step()\n",
    "            \n",
    "            if batch_idx % args.log_interval == 0 or batch_idx==len(client['trainset'])-1:\n",
    "#                 loss = loss.get() \n",
    "                print('Model [{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    client['hook'].id,\n",
    "                    epoch, (batch_idx+1) * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                    100. * (batch_idx+1) / len(client['trainset']), loss))\n",
    "                \n",
    "#     client['model'].get() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc1b60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for d in test_loader:\n",
    "            data = d['image']\n",
    "            target = d['label']\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if(str(device)=='cuda'):\n",
    "                model.cuda()\n",
    "            output = model(data.float())\n",
    "            test_loss += F.nll_loss(output, target.squeeze(1), reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaca5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ceb3ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:518: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/opacus/privacy_engine.py:195: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n",
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:560: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================================\n",
      "[round] =  1 / 1000\n",
      "===================================================================\n",
      "* [client count] =  1 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model [client4] Train Epoch: 1 [16/304 (5%)]\tLoss: 15.350685\n",
      "Model [client4] Train Epoch: 1 [176/304 (58%)]\tLoss: 1.007448\n",
      "Model [client4] Train Epoch: 1 [304/304 (100%)]\tLoss: 1.059994\n",
      "* [client_train_time] =  0:00:04\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 8\n",
      "Model [client5] Train Epoch: 1 [16/304 (5%)]\tLoss: 9.434830\n",
      "Model [client5] Train Epoch: 1 [176/304 (58%)]\tLoss: 1.077571\n",
      "Model [client5] Train Epoch: 1 [304/304 (100%)]\tLoss: 1.104970\n",
      "* [client_train_time] =  0:00:04\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  3 / 8\n",
      "Model [client9] Train Epoch: 1 [16/304 (5%)]\tLoss: 11.853172\n",
      "Model [client9] Train Epoch: 1 [176/304 (58%)]\tLoss: 0.917275\n",
      "Model [client9] Train Epoch: 1 [304/304 (100%)]\tLoss: 0.674404\n",
      "* [client_train_time] =  0:00:04\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  4 / 8\n",
      "Model [client2] Train Epoch: 1 [16/304 (5%)]\tLoss: 11.836292\n",
      "Model [client2] Train Epoch: 1 [176/304 (58%)]\tLoss: 1.342202\n",
      "Model [client2] Train Epoch: 1 [304/304 (100%)]\tLoss: 0.987888\n",
      "* [client_train_time] =  0:00:04\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  5 / 8\n",
      "Model [client1] Train Epoch: 1 [16/304 (5%)]\tLoss: 9.146412\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.torch_seed)\n",
    "global_model = Net()\n",
    "\n",
    "for client in clients:\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr)\n",
    "    client['pengine'] = PrivacyEngine(\n",
    "                                       client['model'],\n",
    "                                       batch_size=args.local_batches,\n",
    "                                       sample_size=len(client['trainset']),\n",
    "                                       alphas=range(2,32),\n",
    "                                       noise_multiplier=0,\n",
    "                                       max_grad_norm=1000\n",
    "                                    )\n",
    "    client['pengine'].attach(client['optim']) \n",
    "    \n",
    "# start training model\n",
    "training_start_time = time.time()\n",
    "for fed_round in range(args.rounds):\n",
    "    print(\"\")\n",
    "    print(\"===================================================================\")\n",
    "    print(\"[round] = \", fed_round+1, \"/\", args.rounds)\n",
    "    print(\"===================================================================\")\n",
    "    \n",
    "    round_train_start_time = time.time()\n",
    "    \n",
    "#     uncomment if you want a randome fraction for C every round\n",
    "#     args.C = float(format(np.random.random(), '.1f'))    \n",
    "    \n",
    "    # number of selected clients\n",
    "    m = int(max(args.C * args.clients, 1))\n",
    "\n",
    "    # Selected devices\n",
    "    np.random.seed(fed_round)\n",
    "    selected_clients_inds = np.random.choice(range(len(clients)), m, replace=False)\n",
    "    selected_clients = [clients[i] for i in selected_clients_inds]\n",
    "    \n",
    "    # Active devices\n",
    "    np.random.seed(fed_round)\n",
    "    active_clients_inds = np.random.choice(selected_clients_inds, int((1-args.drop_rate) * m), replace=False)\n",
    "    active_clients = [clients[i] for i in active_clients_inds]\n",
    "    \n",
    "    # Training \n",
    "    client_cnt = 0\n",
    "    for client in active_clients:\n",
    "        print(\"* [client count] = \", client_cnt+1 , \"/\", len(active_clients))\n",
    "        client_train_start_time = time.time()\n",
    "        ClientUpdate(args, device, client)\n",
    "        client_cnt += 1\n",
    "        client_train_time = round(time.time()-client_train_start_time)\n",
    "        print(\"* [client_train_time] = \", str(timedelta(seconds=(client_train_time))))\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "    \n",
    "#         # Testing \n",
    "#         for client in active_clients:\n",
    "#             test(args, client['model'], device, client['testset'], client['hook'].id)\n",
    "    \n",
    "    # Averaging \n",
    "    global_model = averageModels(global_model, active_clients)\n",
    "    \n",
    "    # Testing the average model\n",
    "    acc = test(args, global_model, device, global_test_loader, 'Global')\n",
    "    writer.add_scalar(\"Accuracy/train\", acc, fed_round)\n",
    "    writer.flush()\n",
    "            \n",
    "    # Share the global model with the clients\n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(global_model.state_dict())\n",
    "        \n",
    "    # training time per round\n",
    "    total_train_time = round(time.time()-training_start_time)\n",
    "    round_train_time = round(time.time()-round_train_start_time)\n",
    "    print(\"** [total train time]: \", str(timedelta(seconds=total_train_time)))\n",
    "    print(\"** [round train time]: \", str(timedelta(seconds=round_train_time)))\n",
    "    \n",
    "    if (args.save_model and fed_round%args.save_model_interval==0 and fed_round!=0):\n",
    "        now = datetime.now() \n",
    "        date = now.strftime(\"%Y_%m_%d_%H%M\")\n",
    "        torch.save(global_model.state_dict(), date + \"_FedAvg_with_DP_round_\" + str(fed_round) + \".pth\")\n",
    "        print(\"model saved : \"+ date +\"_FedAvg_with_DP_round_\" + str(fed_round) + \".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eff631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard open \n",
    "# tensorboard --logdir=/home/citi302/Desktop/Codefolder/FL_DP_covid/runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
