{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aadf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "from opacus import PrivacyEngine\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importlib\n",
    "importlib.import_module('FLDataset_DatasetFolder')\n",
    "from FLDataset_DatasetFolder import load_dataset, getActualImgs, npy_loader\n",
    "from utils import averageModels\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 3012\n",
    "        self.clients = 3\n",
    "        self.rounds = 61\n",
    "        self.epochs = 1\n",
    "        self.local_batches = 20\n",
    "        self.lr = 0.01\n",
    "        self.dropout1 = 0.25\n",
    "        self.dropout2 = 0.5\n",
    "        self.C = 0.66\n",
    "        self.drop_rate = 0.1\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'iid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = True\n",
    "        self.save_model = False\n",
    "        self.save_model_interval = 500\n",
    "        self.del_runs = True\n",
    "        self.acc_csv = True\n",
    "        self.acc_file = '0609_3clients_DP_1.1_clip_60_npy.csv'\n",
    "        self.loss_csv = False\n",
    "        self.loss_file = '0608_3clients_DP_0.5_npy.csv'\n",
    "        # number of classes per client on non iid case \n",
    "        self.noniid_classnum = 1\n",
    "        # transform\n",
    "        self.transform = transforms.Compose([\n",
    "                                    transforms.ToPILImage(),\n",
    "#                                     transforms.Grayscale(num_output_channels=1),\n",
    "                                    transforms.Resize((32,32)),\n",
    "                                    transforms.ToTensor()])\n",
    "        # number of classes\n",
    "        self.c_num = 3\n",
    "        # Opacus get privacy spent DELTA\n",
    "        self.delta = 0.0001\n",
    "        # epsilon record\n",
    "        self.eps = []\n",
    "        self.eps_record = []\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete files in runs (Tensorboard)\n",
    "if args.del_runs==True:\n",
    "    folder = 'runs'\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create accuracy csv file\n",
    "def acc_csv(args, rnd, acc):\n",
    "    if args.acc_csv==True:\n",
    "        with open(\"acc_csv_files/\"+args.acc_file, 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([rnd, acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fbbd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss csv file\n",
    "def loss_csv(args, rnd, loss):\n",
    "    if args.loss_csv==True:\n",
    "        with open(\"loss_csv_files/\"+args.loss_file, 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([rnd, loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10774e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "clients = []\n",
    "\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})\n",
    "\n",
    "print(clients)\n",
    "print(\"number of clients : \", len(clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train, train_group = load_dataset(args.clients, \\\n",
    "                                         args.iid, \\\n",
    "                                         args.transform, \\\n",
    "                                         args.c_num, \\\n",
    "                                         args.noniid_classnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c107d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(global_train))\n",
    "print(type(global_train))\n",
    "print(len(train_group))\n",
    "print(type(train_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a549df0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for inx, client in enumerate(clients):\n",
    "    trainset_ind_list = list(train_group[inx])\n",
    "    print(\"len(client\", str(inx), \"train set) = \", len(trainset_ind_list))\n",
    "    client['trainset'] = getActualImgs(global_train, trainset_ind_list, args.local_batches)\n",
    "    client['samples'] = len(trainset_ind_list) / args.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071cf071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "data_path = \"./FinalCovid19Dataset_npy/test\"\n",
    "global_test_dataset = datasets.DatasetFolder(\n",
    "                                                root=data_path,\n",
    "                                                loader=npy_loader,\n",
    "                                                extensions=tuple(['.npy']),\n",
    "                                                transform=args.transform\n",
    "                                            )\n",
    "# global_test_dataset = CovidDataset('./test.csv', transform=transforms.Compose([Rescale(32), ToTensor()]))\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True, drop_last=True)\n",
    "print(len(global_test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6974d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3,\n",
    "                               out_channels = 32,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "#         self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32,\n",
    "                               out_channels = 64,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "        self.fc1 = nn.Linear(14*14*64, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         x = self.conv1_bn(x)\n",
    "        x = F.relu(self.conv2(x))        \n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, p=args.dropout1)\n",
    "        x = x.view(-1, 14*14*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=args.dropout2)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientUpdate(args, device, client):\n",
    "    client['model'].train()\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        for batch_idx, (data, target) in enumerate(client['trainset']):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            client['optim'].zero_grad()\n",
    "            output = client['model'](data)\n",
    "            loss = client['criterion'](output, target)\n",
    "            loss.backward()\n",
    "            \n",
    "            client['optim'].step()\n",
    "            \n",
    "            \n",
    "            if batch_idx % args.log_interval == 0 or batch_idx==len(client['trainset'])-1:\n",
    "                print('Model [{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    client['hook'].id,\n",
    "                    epoch, (batch_idx+1) * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                    100. * (batch_idx+1) / len(client['trainset']), loss.item()/args.log_interval))\n",
    "                \n",
    "        eps, alpha = client['optim'].privacy_engine.get_privacy_spent(args.delta)\n",
    "        print(f\"(ε = {eps:.2f}, δ = {args.delta}) for α = {alpha}\")\n",
    "        args.eps.append(round(eps,2))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d8cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "#             data = d['image']\n",
    "#             target = d['label']\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if(str(device)=='cuda'):\n",
    "                model.cuda()\n",
    "            output = model(data.float())\n",
    "#             test_loss += F.nll_loss(output, target.squeeze(1), reduction='sum').item() # sum up batch loss\n",
    "            loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target).item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset), test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cb2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de8e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.torch_seed)\n",
    "global_model = Net().to(device)\n",
    "summary(global_model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "for client in clients:\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr)\n",
    "    client['criterion'] = nn.CrossEntropyLoss(reduction='mean')\n",
    "    client['pengine'] = PrivacyEngine(\n",
    "                                       client['model'],\n",
    "                                       batch_size=args.local_batches,\n",
    "                                       sample_size=len(client['trainset']),\n",
    "                                       sample_rate=args.C,\n",
    "                                       alphas=[2,3,4,5,6,7,8,10,11,12,14,16,20,24,28,32,64,256],\n",
    "                                       noise_multiplier=1.1,\n",
    "                                       max_grad_norm=0.05\n",
    "                                    )\n",
    "    client['pengine'].attach(client['optim'])\n",
    "    \n",
    "# start training model\n",
    "training_start_time = time.time()\n",
    "for fed_round in range(args.rounds):\n",
    "    print(\"\")\n",
    "    print(\"===================================================================\")\n",
    "    print(\"[round] = \", fed_round+1, \"/\", args.rounds)\n",
    "    print(\"===================================================================\")\n",
    "    \n",
    "    round_train_start_time = time.time()\n",
    "    \n",
    "#     uncomment if you want a randome fraction for C every round\n",
    "#     args.C = float(format(np.random.random(), '.1f'))    \n",
    "    \n",
    "    # number of selected clients\n",
    "    m = int(max(math.ceil(args.C * args.clients), 1))\n",
    "\n",
    "    # Selected devices\n",
    "    np.random.seed(fed_round)\n",
    "#     m = 2\n",
    "    selected_clients_inds = np.random.choice(range(len(clients)), m, replace=False)\n",
    "    selected_clients = [clients[i] for i in selected_clients_inds]\n",
    "    \n",
    "    # Active devices\n",
    "#     np.random.seed(fed_round)\n",
    "#     active_clients_inds = np.random.choice(selected_clients_inds, int((1-args.drop_rate) * m), replace=False)\n",
    "#     active_clients = [clients[i] for i in active_clients_inds]\n",
    "    active_clients = selected_clients\n",
    "    \n",
    "    # Training \n",
    "    client_cnt = 0\n",
    "    args.eps = []\n",
    "    for client in active_clients:\n",
    "        print(\"* [client count] = \", client_cnt+1 , \"/\", len(active_clients))\n",
    "        client_train_start_time = time.time()\n",
    "        ClientUpdate(args, device, client)\n",
    "        client_cnt += 1\n",
    "        client_train_time = round(time.time()-client_train_start_time)\n",
    "        print(\"* [client_train_time] = \", str(timedelta(seconds=(client_train_time))))\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "    \n",
    "    # print eps mean\n",
    "    print(\"epsilon mean: \", sum(args.eps) / len(args.eps))\n",
    "    args.eps_record.append(sum(args.eps) / len(args.eps))\n",
    "    \n",
    "    # Averaging \n",
    "#     print(\"active clients: \", active_clients)\n",
    "    global_model = averageModels(global_model, active_clients)\n",
    "    \n",
    "    # Testing the average model\n",
    "    client_test_start_time = time.time()\n",
    "    acc, loss = test(args, global_model, device, global_test_loader, 'Global')\n",
    "    client_test_time = round(time.time()-client_test_start_time)\n",
    "    print(\"* [global_test_time] = \", str(timedelta(seconds=(client_test_time))))\n",
    "    \n",
    "    writer.add_scalar(\"Accuracy/train\", acc, fed_round)\n",
    "    writer.flush()\n",
    "    acc_csv(args, fed_round, acc)\n",
    "    loss_csv(args, fed_round, loss)\n",
    "            \n",
    "    # Share the global model with the clients\n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(global_model.state_dict())\n",
    "        \n",
    "    # training time per round\n",
    "    total_train_time = round(time.time()-training_start_time)\n",
    "    round_train_time = round(time.time()-round_train_start_time)\n",
    "    print(\"** [total train time]: \", str(timedelta(seconds=total_train_time)))\n",
    "    print(\"** [round train time]: \", str(timedelta(seconds=round_train_time)))\n",
    "    \n",
    "    if (args.save_model and fed_round%args.save_model_interval==0 and fed_round!=0):\n",
    "        now = datetime.now() \n",
    "        date = now.strftime(\"%Y_%m_%d_%H%M\")\n",
    "        torch.save(global_model.state_dict(), date + \"_FedAvg_with_DP_round_\" + str(fed_round) + \".pth\")\n",
    "        print(\"model saved : \"+ date +\"_FedAvg_with_DP_round_\" + str(fed_round) + \"10clients.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args.eps_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = list(range(0, 61))\n",
    "plt.title(\"FL with Differential Privacy Training Accuracy\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Rounds\")\n",
    "\n",
    "plt.plot(x1, args.eps_record, label='0.0')\n",
    "plt.grid(color = 'gray', linestyle = '--')\n",
    "plt.legend(bbox_to_anchor=(1.03, 1.03), loc='upper left', \\\n",
    "           title=\"Noise Multiplier\")\n",
    "plt.ylim(20, 8000)\n",
    "plt.xticks(np.arange(0,61,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(61):\n",
    "    with open(\"1.1_clip0.05.csv\", 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([i, args.eps_record[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059ee5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
