{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8957a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import syft as sy\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "from opacus import PrivacyEngine\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from torchsummary import summary\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "import importlib\n",
    "importlib.import_module('FLDataset')\n",
    "from FLDataset import load_dataset, getActualImgs, CovidDataset, Rescale, ToTensor\n",
    "from utils import averageModels, averageGradients\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306fa383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 3012\n",
    "        self.clients = 3\n",
    "        self.rounds = 1001\n",
    "        self.epochs = 1\n",
    "        self.local_batches = 20\n",
    "        self.lr = 0.01\n",
    "        self.dropout1 = 0.25\n",
    "        self.dropout2 = 0.5\n",
    "        self.C = 0.66\n",
    "        self.drop_rate = 0.1\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 10\n",
    "        self.iid = 'noniid'\n",
    "        self.split_size = int(self.images / self.clients)\n",
    "        self.samples = self.split_size / self.images \n",
    "        self.use_cuda = True\n",
    "        self.save_model = False\n",
    "        self.save_model_interval = 500\n",
    "        self.clip = 1\n",
    "        self.del_runs = False\n",
    "        self.acc_csv = False\n",
    "        self.acc_file = '0526_30clients.csv'\n",
    "        # number of classes per client on non iid case \n",
    "        self.noniid_classnum = 2\n",
    "        # data transform\n",
    "        self.transform = transforms.Compose([Rescale(32), ToTensor()])\n",
    "        # number of classes\n",
    "        self.c_num = 3\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffc6da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete files in runs (Tensorboard)\n",
    "if args.del_runs==True:\n",
    "    folder = 'runs'\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8ba0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create accuracy csv file\n",
    "def acc_csv(args, rnd, acc):\n",
    "    if args.acc_csv==True:\n",
    "        with open(\"acc_csv_files/\"+args.acc_file, 'a') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([rnd, acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb6380cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'hook': <VirtualWorker id:client1 #objects:0>}, {'hook': <VirtualWorker id:client2 #objects:0>}, {'hook': <VirtualWorker id:client3 #objects:0>}]\n",
      "number of clients :  3\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)\n",
    "clients = []\n",
    "\n",
    "for i in range(args.clients):\n",
    "    clients.append({'hook': sy.VirtualWorker(hook, id=\"client{}\".format(i+1))})\n",
    "\n",
    "print(clients)\n",
    "print(\"number of clients : \", len(clients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3438f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In covid non IID: unsorted labels get_labels=  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "In covid non IID: shuffled indices =  [1457 1223 2322 ... 2996   78   60]\n",
      "In covid non IID: indeces_unsortedlabels  [[1457 1223 2322 ... 2996   78   60]\n",
      " [   2    2    0 ...    0    1    1]]\n",
      "In covid non IID: indeces_labels  [[2103 2792 3011 ... 1874 1887 1534]\n",
      " [   0    0    0 ...    2    2    2]]\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "(1, 2)\n",
      "comb  [(0, 1), (0, 2), (1, 2)]\n",
      "client_classes  [[0 1]\n",
      " [0 2]\n",
      " [1 2]]\n",
      "label count  Counter({0: 2, 1: 2, 2: 2})\n",
      "users_dict  {0: [], 1: [], 2: []}\n"
     ]
    }
   ],
   "source": [
    "global_train, train_group= load_dataset(args.clients, \\\n",
    "                                                                  args.iid, \\\n",
    "                                                                  args.transform, \\\n",
    "                                                                  args.c_num, \\\n",
    "                                                                  args.noniid_classnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb44b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3012\n",
      "<class 'FLDataset.CovidDataset'>\n",
      "3\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(len(global_train))\n",
    "print(type(global_train))\n",
    "print(len(train_group))\n",
    "print(type(train_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3c1c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(client 0 train set) =  1004\n",
      "len(client 1 train set) =  1004\n",
      "len(client 2 train set) =  1004\n"
     ]
    }
   ],
   "source": [
    "for inx, client in enumerate(clients):\n",
    "    trainset_ind_list = list(train_group[inx])\n",
    "    print(\"len(client\", str(inx), \"train set) = \", len(trainset_ind_list))\n",
    "    client['trainset'] = getActualImgs(global_train, trainset_ind_list, args.local_batches)\n",
    "#     client['testset'] = getActualImgs(global_test, list(test_group[inx]), args.local_batches)\n",
    "    client['samples'] = len(trainset_ind_list) / args.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4fa186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "global_test_dataset = CovidDataset('./test.csv', transform=transforms.Compose([Rescale(32), ToTensor()]))\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True, drop_last=True)\n",
    "print(len(global_test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ec04f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = 32,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "#         self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32,\n",
    "                               out_channels = 64,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "        self.fc1 = nn.Linear(14*14*64, 128)\n",
    "#         self.fc1_bn = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         x = self.conv1_bn(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, p=args.dropout1)\n",
    "        x = x.view(-1, 14*14*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=args.dropout2)\n",
    "#         x = self.fc1_bn(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5cc2498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClientUpdate(args, device, client):\n",
    "    client['model'].train()\n",
    "#     client['model'].send(client['hook'])\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        for batch_idx, (data, target) in enumerate(client['trainset']):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            client['optim'].zero_grad()\n",
    "#             output = client['model'](data.float())\n",
    "#             loss = F.nll_loss(output, target.squeeze(1))\n",
    "            output = client['model'](data)\n",
    "            loss = client['criterion'](output, target.squeeze(1))\n",
    "            loss.backward()\n",
    "            \n",
    "#             print weight \n",
    "#             for name, param in client['model'].named_parameters():\n",
    "#                 if name=='conv1_bn.weight':\n",
    "#                     print(name, param.grad)\n",
    "            \n",
    "#             torch.nn.utils.clip_grad_norm_(client['model'].parameters(), args.clip)\n",
    "            client['optim'].step()\n",
    "            \n",
    "            \n",
    "            if batch_idx % args.log_interval == 0 or batch_idx==len(client['trainset'])-1:\n",
    "#                 loss = loss.get() \n",
    "                print('Model [{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    client['hook'].id,\n",
    "                    epoch, (batch_idx+1) * args.local_batches, len(client['trainset']) * args.local_batches, \n",
    "                    100. * (batch_idx+1) / len(client['trainset']), loss.item()/args.log_interval))\n",
    "                \n",
    "#     client['model'].get() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b48cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, name):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for d in test_loader:\n",
    "            data = d['image']\n",
    "            target = d['label']\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if(str(device)=='cuda'):\n",
    "                model.cuda()\n",
    "            output = model(data.float())\n",
    "#             test_loss += F.nll_loss(output, target.squeeze(1), reduction='sum').item() # sum up batch loss\n",
    "            loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target.squeeze(1)).item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for {} model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        name, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03d7a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a11fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 30, 30]             320\n",
      "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
      "            Linear-3                  [-1, 128]       1,605,760\n",
      "            Linear-4                    [-1, 3]             387\n",
      "================================================================\n",
      "Total params: 1,624,963\n",
      "Trainable params: 1,624,963\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.60\n",
      "Params size (MB): 6.20\n",
      "Estimated Total Size (MB): 6.81\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/syft/frameworks/torch/tensors/interpreters/native.py:414: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  response = command_method(*args_, **kwargs_)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.torch_seed)\n",
    "global_model = Net().to(device)\n",
    "summary(global_model, (1, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/syft/frameworks/torch/hook/hook.py:560: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  current_tensor = hook_self.torch.native_tensor(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================================================\n",
      "[round] =  1 / 1001\n",
      "===================================================================\n",
      "* [client count] =  1 / 2\n",
      "Model [client3] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.142616\n",
      "Model [client3] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.105144\n",
      "Model [client3] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.105144\n",
      "Model [client3] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.120144\n",
      "Model [client3] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.095144\n",
      "Model [client3] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.080144\n",
      "* [client_train_time] =  0:00:15\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 2\n",
      "Model [client2] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.112870\n",
      "Model [client2] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.110144\n",
      "Model [client2] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.135144\n",
      "Model [client2] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.100144\n",
      "Model [client2] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.110144\n",
      "Model [client2] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.105144\n",
      "* [client_train_time] =  0:00:11\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test set: Average loss for Global model: 1.1900, Accuracy: 252/753 (33%)\n",
      "\n",
      "** [total train time]:  0:00:31\n",
      "** [round train time]:  0:00:31\n",
      "\n",
      "===================================================================\n",
      "[round] =  2 / 1001\n",
      "===================================================================\n",
      "* [client count] =  1 / 2\n",
      "Model [client1] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.105144\n",
      "Model [client1] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.100144\n",
      "Model [client1] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.100144\n",
      "Model [client1] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.100144\n",
      "Model [client1] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.095144\n",
      "Model [client1] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.130144\n",
      "* [client_train_time] =  0:00:09\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 2\n",
      "Model [client3] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.090144\n",
      "Model [client3] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.100144\n",
      "Model [client3] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.100144\n",
      "Model [client3] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.115144\n",
      "Model [client3] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.095144\n",
      "Model [client3] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.105144\n",
      "* [client_train_time] =  0:00:15\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test set: Average loss for Global model: 1.1980, Accuracy: 246/753 (33%)\n",
      "\n",
      "** [total train time]:  0:01:00\n",
      "** [round train time]:  0:00:29\n",
      "\n",
      "===================================================================\n",
      "[round] =  3 / 1001\n",
      "===================================================================\n",
      "* [client count] =  1 / 2\n",
      "Model [client3] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.105144\n",
      "Model [client3] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.120144\n",
      "Model [client3] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.135144\n",
      "Model [client3] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.095144\n",
      "Model [client3] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.120144\n",
      "Model [client3] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.130144\n",
      "* [client_train_time] =  0:00:15\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 2\n",
      "Model [client2] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.155144\n",
      "Model [client2] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.155144\n",
      "Model [client2] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.155144\n",
      "Model [client2] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.155144\n",
      "Model [client2] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.155144\n",
      "Model [client2] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.155144\n",
      "* [client_train_time] =  0:00:11\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test set: Average loss for Global model: 1.2001, Accuracy: 244/753 (32%)\n",
      "\n",
      "** [total train time]:  0:01:31\n",
      "** [round train time]:  0:00:31\n",
      "\n",
      "===================================================================\n",
      "[round] =  4 / 1001\n",
      "===================================================================\n",
      "* [client count] =  1 / 2\n",
      "Model [client2] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.130142\n",
      "Model [client2] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.100144\n",
      "Model [client2] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.105144\n",
      "Model [client2] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.100144\n",
      "Model [client2] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.100144\n",
      "Model [client2] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.105144\n",
      "* [client_train_time] =  0:00:11\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 2\n",
      "Model [client1] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.135143\n",
      "Model [client1] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.105144\n",
      "Model [client1] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.105144\n",
      "Model [client1] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.120144\n",
      "Model [client1] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.090144\n",
      "Model [client1] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.105144\n",
      "* [client_train_time] =  0:00:09\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test set: Average loss for Global model: 1.1966, Accuracy: 247/753 (33%)\n",
      "\n",
      "** [total train time]:  0:01:56\n",
      "** [round train time]:  0:00:25\n",
      "\n",
      "===================================================================\n",
      "[round] =  5 / 1001\n",
      "===================================================================\n",
      "* [client count] =  1 / 2\n",
      "Model [client2] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.125144\n",
      "Model [client2] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.110144\n",
      "Model [client2] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.100144\n",
      "Model [client2] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.115144\n",
      "Model [client2] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.100144\n",
      "Model [client2] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.130144\n",
      "* [client_train_time] =  0:00:11\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 2\n",
      "Model [client1] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.150144\n",
      "Model [client1] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.155144\n",
      "* [client_train_time] =  0:00:09\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test set: Average loss for Global model: 1.1871, Accuracy: 254/753 (34%)\n",
      "\n",
      "** [total train time]:  0:02:20\n",
      "** [round train time]:  0:00:25\n",
      "\n",
      "===================================================================\n",
      "[round] =  6 / 1001\n",
      "===================================================================\n",
      "* [client count] =  1 / 2\n",
      "Model [client1] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.155144\n",
      "* [client_train_time] =  0:00:09\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 2\n",
      "Model [client2] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.105144\n",
      "Model [client2] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.115144\n",
      "Model [client2] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.115144\n",
      "Model [client2] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.125144\n",
      "Model [client2] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.100144\n",
      "Model [client2] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.105144\n",
      "* [client_train_time] =  0:00:11\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test set: Average loss for Global model: 1.1980, Accuracy: 246/753 (33%)\n",
      "\n",
      "** [total train time]:  0:02:45\n",
      "** [round train time]:  0:00:25\n",
      "\n",
      "===================================================================\n",
      "[round] =  7 / 1001\n",
      "===================================================================\n",
      "* [client count] =  1 / 2\n",
      "Model [client1] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.155144\n",
      "Model [client1] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.150144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model [client1] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.100144\n",
      "Model [client1] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.105144\n",
      "* [client_train_time] =  0:00:09\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 2\n",
      "Model [client2] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.095144\n",
      "Model [client2] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.110144\n",
      "Model [client2] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.110144\n",
      "Model [client2] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.110144\n",
      "Model [client2] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.100144\n",
      "Model [client2] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.105144\n",
      "* [client_train_time] =  0:00:11\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Test set: Average loss for Global model: 1.2126, Accuracy: 235/753 (31%)\n",
      "\n",
      "** [total train time]:  0:03:09\n",
      "** [round train time]:  0:00:25\n",
      "\n",
      "===================================================================\n",
      "[round] =  8 / 1001\n",
      "===================================================================\n",
      "* [client count] =  1 / 2\n",
      "Model [client3] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.105144\n",
      "Model [client3] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.095144\n",
      "Model [client3] Train Epoch: 1 [420/1020 (41%)]\tLoss: 0.115144\n",
      "Model [client3] Train Epoch: 1 [620/1020 (61%)]\tLoss: 0.095144\n",
      "Model [client3] Train Epoch: 1 [820/1020 (80%)]\tLoss: 0.090144\n",
      "Model [client3] Train Epoch: 1 [1020/1020 (100%)]\tLoss: 0.130144\n",
      "* [client_train_time] =  0:00:15\n",
      "---------------------------------------------------------------\n",
      "* [client count] =  2 / 2\n",
      "Model [client2] Train Epoch: 1 [20/1020 (2%)]\tLoss: 0.125144\n",
      "Model [client2] Train Epoch: 1 [220/1020 (22%)]\tLoss: 0.135104\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for client in clients:\n",
    "    torch.manual_seed(args.torch_seed)\n",
    "    client['model'] = Net().to(device)\n",
    "    client['optim'] = optim.SGD(client['model'].parameters(), lr=args.lr, momentum = 0.8)\n",
    "    client['criterion'] = nn.CrossEntropyLoss(reduction='mean')\n",
    "#     client['pengine'] = PrivacyEngine(\n",
    "#                                        client['model'],\n",
    "#                                        batch_size=args.local_batches,\n",
    "#                                        sample_size=len(client['trainset']),\n",
    "#                                        alphas=range(2,32),\n",
    "#                                        noise_multiplier=0,\n",
    "#                                        max_grad_norm=1000\n",
    "#                                     )\n",
    "#     client['pengine'].attach(client['optim']) \n",
    "    \n",
    "# start training model\n",
    "training_start_time = time.time()\n",
    "for fed_round in range(args.rounds):\n",
    "    print(\"\")\n",
    "    print(\"===================================================================\")\n",
    "    print(\"[round] = \", fed_round+1, \"/\", args.rounds)\n",
    "    print(\"===================================================================\")\n",
    "    \n",
    "    round_train_start_time = time.time()\n",
    "    \n",
    "#     uncomment if you want a randome fraction for C every round\n",
    "#     args.C = float(format(np.random.random(), '.1f'))    \n",
    "    \n",
    "    # number of selected clients\n",
    "    m = int(max(math.ceil(args.C * args.clients), 1))\n",
    "\n",
    "    # Selected devices\n",
    "    np.random.seed(fed_round)\n",
    "    selected_clients_inds = np.random.choice(range(len(clients)), m, replace=False)\n",
    "    selected_clients = [clients[i] for i in selected_clients_inds]\n",
    "    \n",
    "    # Active devices\n",
    "#     np.random.seed(fed_round)\n",
    "#     active_clients_inds = np.random.choice(selected_clients_inds, int((1-args.drop_rate) * m), replace=False)\n",
    "#     active_clients = [clients[i] for i in active_clients_inds]\n",
    "    active_clients = selected_clients\n",
    "    \n",
    "    # Training \n",
    "    client_cnt = 0\n",
    "    for client in active_clients:\n",
    "        print(\"* [client count] = \", client_cnt+1 , \"/\", len(active_clients))\n",
    "        client_train_start_time = time.time()\n",
    "        ClientUpdate(args, device, client)\n",
    "        client_cnt += 1\n",
    "        client_train_time = round(time.time()-client_train_start_time)\n",
    "        print(\"* [client_train_time] = \", str(timedelta(seconds=(client_train_time))))\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "    \n",
    "#         # Testing \n",
    "#         for client in active_clients:\n",
    "#             test(args, client['model'], device, client['testset'], client['hook'].id)\n",
    "    \n",
    "    # Averaging \n",
    "#     print(\"active clients: \", active_clients)\n",
    "    global_model = averageModels(global_model, active_clients)\n",
    "    \n",
    "    # Testing the average model\n",
    "    acc = test(args, global_model, device, global_test_loader, 'Global')\n",
    "    writer.add_scalar(\"Accuracy/train\", acc, fed_round)\n",
    "    writer.flush()\n",
    "    acc_csv(args, fed_round, acc)\n",
    "            \n",
    "    # Share the global model with the clients\n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(global_model.state_dict())\n",
    "        \n",
    "    # training time per round\n",
    "    total_train_time = round(time.time()-training_start_time)\n",
    "    round_train_time = round(time.time()-round_train_start_time)\n",
    "    print(\"** [total train time]: \", str(timedelta(seconds=total_train_time)))\n",
    "    print(\"** [round train time]: \", str(timedelta(seconds=round_train_time)))\n",
    "    \n",
    "    if (args.save_model and fed_round%args.save_model_interval==0 and fed_round!=0):\n",
    "        now = datetime.now() \n",
    "        date = now.strftime(\"%Y_%m_%d_%H%M\")\n",
    "        torch.save(global_model.state_dict(), date + \"_FedAvg_with_DP_round_\" + str(fed_round) + \".pth\")\n",
    "        print(\"model saved : \"+ date +\"_FedAvg_with_DP_round_\" + str(fed_round) + \"10clients.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard open \n",
    "# tensorboard --logdir=/home/citi302/Desktop/Codefolder/FL_DP_covid/runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
