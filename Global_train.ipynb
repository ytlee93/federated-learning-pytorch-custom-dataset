{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d7ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e877aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 3012\n",
    "        self.epochs = 100\n",
    "        self.clients = 1\n",
    "        self.local_batches = 20\n",
    "        self.lr = 0.01\n",
    "        self.iid = 'iid'\n",
    "        self.dropout1 = 0.25\n",
    "        self.dropout2 = 0.5\n",
    "        self.drop_rate = 0.1\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 100\n",
    "        self.use_cuda = True\n",
    "        self.save_model = False\n",
    "        self.save_model_interval = 200\n",
    "        self.clip = 1\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff1b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)\n",
    "        self.transform = transform\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.data_info.iloc[idx, 0]\n",
    "        image = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)\n",
    "        label = self.data_info.iloc[idx, 1]\n",
    "        label = np.array([label])\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        img = cv2.resize(image, (self.output_size, self.output_size))\n",
    "\n",
    "        return {'image': img, 'label': label}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        \n",
    "        tensor_img = torch.from_numpy(image)\n",
    "        tensor_img = tensor_img.unsqueeze(dim=0)\n",
    "        tensor_img = tensor_img.type('torch.FloatTensor')\n",
    "        tensor_lb = torch.from_numpy(label)\n",
    "\n",
    "        return {'image': tensor_img,\n",
    "                'label': tensor_lb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da83ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train_dataset = CovidDataset('./train.csv', transform=transforms.Compose([Rescale(32), ToTensor()]))\n",
    "global_train_loader = DataLoader(global_train_dataset, batch_size=args.local_batches, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c597b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_test_dataset = CovidDataset('./test.csv', transform=transforms.Compose([Rescale(32), ToTensor()]))\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66ad4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = 32,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32,\n",
    "                               out_channels = 64,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "        self.fc1 = nn.Linear(14*14*64, 128)\n",
    "        self.fc1_bn = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         x = self.conv1_bn(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, p=args.dropout1)\n",
    "        x = x.view(-1, 14*14*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=args.dropout2)\n",
    "#         x = self.fc1_bn(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462dbe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, device, model, optimizer, criterion, train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            data = batch['image']\n",
    "            target = batch['label']\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.squeeze(1))\n",
    "            loss.backward()\n",
    "    \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % args.log_interval == 0 or batch_idx==len(train_loader)-1:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, \n",
    "                    batch_idx * args.local_batches, \n",
    "                    len(train_loader) * args.local_batches, \n",
    "                    100. * (batch_idx+1) / len(train_loader), \n",
    "                    loss.item()/args.log_interval))\n",
    "                \n",
    "        acc = test(args, model, device, global_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24834e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for d in test_loader:\n",
    "            data = d['image']\n",
    "            target = d['label']\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if(str(device)=='cuda'):\n",
    "                model.cuda()\n",
    "            output = model(data.float())\n",
    "#             test_loss += F.nll_loss(output, target.squeeze(1), reduction='sum').item() # sum up batch loss\n",
    "            loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target.squeeze(1)).item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for  model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5af5f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum = 0.8)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5a22ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(global_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211abf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3000 (1%)]\tLoss: 0.012480\n",
      "Train Epoch: 0 [2000/3000 (67%)]\tLoss: 0.011485\n",
      "Train Epoch: 0 [2980/3000 (100%)]\tLoss: 0.013014\n",
      "\n",
      "Test set: Average loss for  model: 1.2021, Accuracy: 242/753 (32%)\n",
      "\n",
      "Train Epoch: 1 [0/3000 (1%)]\tLoss: 0.012014\n",
      "Train Epoch: 1 [2000/3000 (67%)]\tLoss: 0.010514\n",
      "Train Epoch: 1 [2980/3000 (100%)]\tLoss: 0.010484\n",
      "\n",
      "Test set: Average loss for  model: 1.1819, Accuracy: 258/753 (34%)\n",
      "\n",
      "Train Epoch: 2 [0/3000 (1%)]\tLoss: 0.011014\n",
      "Train Epoch: 2 [2000/3000 (67%)]\tLoss: 0.012514\n",
      "Train Epoch: 2 [2980/3000 (100%)]\tLoss: 0.011514\n",
      "\n",
      "Test set: Average loss for  model: 1.1991, Accuracy: 245/753 (33%)\n",
      "\n",
      "Train Epoch: 3 [0/3000 (1%)]\tLoss: 0.011514\n",
      "Train Epoch: 3 [2000/3000 (67%)]\tLoss: 0.012014\n",
      "Train Epoch: 3 [2980/3000 (100%)]\tLoss: 0.011506\n",
      "\n",
      "Test set: Average loss for  model: 1.1900, Accuracy: 252/753 (33%)\n",
      "\n",
      "Train Epoch: 4 [0/3000 (1%)]\tLoss: 0.011014\n",
      "Train Epoch: 4 [2000/3000 (67%)]\tLoss: 0.011514\n",
      "Train Epoch: 4 [2980/3000 (100%)]\tLoss: 0.013014\n",
      "\n",
      "Test set: Average loss for  model: 1.1739, Accuracy: 264/753 (35%)\n",
      "\n",
      "Train Epoch: 5 [0/3000 (1%)]\tLoss: 0.013514\n",
      "Train Epoch: 5 [2000/3000 (67%)]\tLoss: 0.011514\n",
      "Train Epoch: 5 [2980/3000 (100%)]\tLoss: 0.012514\n",
      "\n",
      "Test set: Average loss for  model: 1.1910, Accuracy: 249/753 (33%)\n",
      "\n",
      "Train Epoch: 6 [0/3000 (1%)]\tLoss: 0.012014\n",
      "Train Epoch: 6 [2000/3000 (67%)]\tLoss: 0.012514\n",
      "Train Epoch: 6 [2980/3000 (100%)]\tLoss: 0.014014\n",
      "\n",
      "Test set: Average loss for  model: 1.1976, Accuracy: 246/753 (33%)\n",
      "\n",
      "Train Epoch: 7 [0/3000 (1%)]\tLoss: 0.011014\n",
      "Train Epoch: 7 [2000/3000 (67%)]\tLoss: 0.012286\n",
      "Train Epoch: 7 [2980/3000 (100%)]\tLoss: 0.011014\n",
      "\n",
      "Test set: Average loss for  model: 1.1574, Accuracy: 276/753 (37%)\n",
      "\n",
      "Train Epoch: 8 [0/3000 (1%)]\tLoss: 0.011514\n",
      "Train Epoch: 8 [2000/3000 (67%)]\tLoss: 0.011514\n",
      "Train Epoch: 8 [2980/3000 (100%)]\tLoss: 0.011014\n",
      "\n",
      "Test set: Average loss for  model: 1.1963, Accuracy: 247/753 (33%)\n",
      "\n",
      "Train Epoch: 9 [0/3000 (1%)]\tLoss: 0.010014\n",
      "Train Epoch: 9 [2000/3000 (67%)]\tLoss: 0.012307\n",
      "Train Epoch: 9 [2980/3000 (100%)]\tLoss: 0.009257\n",
      "\n",
      "Test set: Average loss for  model: 0.8565, Accuracy: 495/753 (66%)\n",
      "\n",
      "Train Epoch: 10 [0/3000 (1%)]\tLoss: 0.008767\n",
      "Train Epoch: 10 [2000/3000 (67%)]\tLoss: 0.006552\n",
      "Train Epoch: 10 [2980/3000 (100%)]\tLoss: 0.006589\n",
      "\n",
      "Test set: Average loss for  model: 0.6737, Accuracy: 641/753 (85%)\n",
      "\n",
      "Train Epoch: 11 [0/3000 (1%)]\tLoss: 0.006324\n",
      "Train Epoch: 11 [2000/3000 (67%)]\tLoss: 0.007620\n",
      "Train Epoch: 11 [2980/3000 (100%)]\tLoss: 0.006285\n",
      "\n",
      "Test set: Average loss for  model: 0.6774, Accuracy: 631/753 (84%)\n",
      "\n",
      "Train Epoch: 12 [0/3000 (1%)]\tLoss: 0.006265\n",
      "Train Epoch: 12 [2000/3000 (67%)]\tLoss: 0.007013\n",
      "Train Epoch: 12 [2980/3000 (100%)]\tLoss: 0.006174\n",
      "\n",
      "Test set: Average loss for  model: 0.6464, Accuracy: 662/753 (88%)\n",
      "\n",
      "Train Epoch: 13 [0/3000 (1%)]\tLoss: 0.006700\n",
      "Train Epoch: 13 [2000/3000 (67%)]\tLoss: 0.006771\n",
      "Train Epoch: 13 [2980/3000 (100%)]\tLoss: 0.006565\n",
      "\n",
      "Test set: Average loss for  model: 0.6356, Accuracy: 670/753 (89%)\n",
      "\n",
      "Train Epoch: 14 [0/3000 (1%)]\tLoss: 0.007926\n",
      "Train Epoch: 14 [2000/3000 (67%)]\tLoss: 0.006157\n",
      "Train Epoch: 14 [2980/3000 (100%)]\tLoss: 0.007101\n",
      "\n",
      "Test set: Average loss for  model: 0.6438, Accuracy: 662/753 (88%)\n",
      "\n",
      "Train Epoch: 15 [0/3000 (1%)]\tLoss: 0.007347\n",
      "Train Epoch: 15 [2000/3000 (67%)]\tLoss: 0.006672\n",
      "Train Epoch: 15 [2980/3000 (100%)]\tLoss: 0.005532\n",
      "\n",
      "Test set: Average loss for  model: 0.6414, Accuracy: 663/753 (88%)\n",
      "\n",
      "Train Epoch: 16 [0/3000 (1%)]\tLoss: 0.005542\n",
      "Train Epoch: 16 [2000/3000 (67%)]\tLoss: 0.006990\n",
      "Train Epoch: 16 [2980/3000 (100%)]\tLoss: 0.006160\n",
      "\n",
      "Test set: Average loss for  model: 0.6409, Accuracy: 664/753 (88%)\n",
      "\n",
      "Train Epoch: 17 [0/3000 (1%)]\tLoss: 0.005958\n",
      "Train Epoch: 17 [2000/3000 (67%)]\tLoss: 0.005968\n",
      "Train Epoch: 17 [2980/3000 (100%)]\tLoss: 0.008564\n",
      "\n",
      "Test set: Average loss for  model: 0.6232, Accuracy: 677/753 (90%)\n",
      "\n",
      "Train Epoch: 18 [0/3000 (1%)]\tLoss: 0.006059\n",
      "Train Epoch: 18 [2000/3000 (67%)]\tLoss: 0.006838\n",
      "Train Epoch: 18 [2980/3000 (100%)]\tLoss: 0.006456\n",
      "\n",
      "Test set: Average loss for  model: 0.6213, Accuracy: 677/753 (90%)\n",
      "\n",
      "Train Epoch: 19 [0/3000 (1%)]\tLoss: 0.006464\n",
      "Train Epoch: 19 [2000/3000 (67%)]\tLoss: 0.006365\n",
      "Train Epoch: 19 [2980/3000 (100%)]\tLoss: 0.006957\n",
      "\n",
      "Test set: Average loss for  model: 0.6182, Accuracy: 682/753 (91%)\n",
      "\n",
      "Train Epoch: 20 [0/3000 (1%)]\tLoss: 0.006377\n",
      "Train Epoch: 20 [2000/3000 (67%)]\tLoss: 0.006006\n",
      "Train Epoch: 20 [2980/3000 (100%)]\tLoss: 0.005787\n",
      "\n",
      "Test set: Average loss for  model: 0.6294, Accuracy: 672/753 (89%)\n",
      "\n",
      "Train Epoch: 21 [0/3000 (1%)]\tLoss: 0.006013\n",
      "Train Epoch: 21 [2000/3000 (67%)]\tLoss: 0.005515\n",
      "Train Epoch: 21 [2980/3000 (100%)]\tLoss: 0.006527\n",
      "\n",
      "Test set: Average loss for  model: 0.6193, Accuracy: 680/753 (90%)\n",
      "\n",
      "Train Epoch: 22 [0/3000 (1%)]\tLoss: 0.007049\n",
      "Train Epoch: 22 [2000/3000 (67%)]\tLoss: 0.005746\n",
      "Train Epoch: 22 [2980/3000 (100%)]\tLoss: 0.006304\n",
      "\n",
      "Test set: Average loss for  model: 0.6088, Accuracy: 688/753 (91%)\n",
      "\n",
      "Train Epoch: 23 [0/3000 (1%)]\tLoss: 0.005515\n",
      "Train Epoch: 23 [2000/3000 (67%)]\tLoss: 0.005544\n",
      "Train Epoch: 23 [2980/3000 (100%)]\tLoss: 0.005985\n",
      "\n",
      "Test set: Average loss for  model: 0.6103, Accuracy: 690/753 (92%)\n",
      "\n",
      "Train Epoch: 24 [0/3000 (1%)]\tLoss: 0.005949\n",
      "Train Epoch: 24 [2000/3000 (67%)]\tLoss: 0.006006\n",
      "Train Epoch: 24 [2980/3000 (100%)]\tLoss: 0.005544\n",
      "\n",
      "Test set: Average loss for  model: 0.6291, Accuracy: 674/753 (90%)\n",
      "\n",
      "Train Epoch: 25 [0/3000 (1%)]\tLoss: 0.006011\n",
      "Train Epoch: 25 [2000/3000 (67%)]\tLoss: 0.006111\n",
      "Train Epoch: 25 [2980/3000 (100%)]\tLoss: 0.005945\n",
      "\n",
      "Test set: Average loss for  model: 0.6183, Accuracy: 681/753 (90%)\n",
      "\n",
      "Train Epoch: 26 [0/3000 (1%)]\tLoss: 0.005987\n",
      "Train Epoch: 26 [2000/3000 (67%)]\tLoss: 0.006517\n",
      "Train Epoch: 26 [2980/3000 (100%)]\tLoss: 0.005610\n",
      "\n",
      "Test set: Average loss for  model: 0.6063, Accuracy: 688/753 (91%)\n",
      "\n",
      "Train Epoch: 27 [0/3000 (1%)]\tLoss: 0.005517\n",
      "Train Epoch: 27 [2000/3000 (67%)]\tLoss: 0.007019\n",
      "Train Epoch: 27 [2980/3000 (100%)]\tLoss: 0.006015\n",
      "\n",
      "Test set: Average loss for  model: 0.6331, Accuracy: 669/753 (89%)\n",
      "\n",
      "Train Epoch: 28 [0/3000 (1%)]\tLoss: 0.006810\n",
      "Train Epoch: 28 [2000/3000 (67%)]\tLoss: 0.005528\n",
      "Train Epoch: 28 [2980/3000 (100%)]\tLoss: 0.006505\n",
      "\n",
      "Test set: Average loss for  model: 0.6054, Accuracy: 694/753 (92%)\n",
      "\n",
      "Train Epoch: 29 [0/3000 (1%)]\tLoss: 0.006546\n",
      "Train Epoch: 29 [2000/3000 (67%)]\tLoss: 0.005515\n",
      "Train Epoch: 29 [2980/3000 (100%)]\tLoss: 0.005515\n",
      "\n",
      "Test set: Average loss for  model: 0.6111, Accuracy: 687/753 (91%)\n",
      "\n",
      "Train Epoch: 30 [0/3000 (1%)]\tLoss: 0.006014\n",
      "Train Epoch: 30 [2000/3000 (67%)]\tLoss: 0.006615\n",
      "Train Epoch: 30 [2980/3000 (100%)]\tLoss: 0.006515\n",
      "\n",
      "Test set: Average loss for  model: 0.6054, Accuracy: 691/753 (92%)\n",
      "\n",
      "Train Epoch: 31 [0/3000 (1%)]\tLoss: 0.005515\n",
      "Train Epoch: 31 [2000/3000 (67%)]\tLoss: 0.005565\n",
      "Train Epoch: 31 [2980/3000 (100%)]\tLoss: 0.005519\n",
      "\n",
      "Test set: Average loss for  model: 0.6024, Accuracy: 693/753 (92%)\n",
      "\n",
      "Train Epoch: 32 [0/3000 (1%)]\tLoss: 0.005717\n",
      "Train Epoch: 32 [2000/3000 (67%)]\tLoss: 0.005528\n",
      "Train Epoch: 32 [2980/3000 (100%)]\tLoss: 0.005515\n",
      "\n",
      "Test set: Average loss for  model: 0.6030, Accuracy: 693/753 (92%)\n",
      "\n",
      "Train Epoch: 33 [0/3000 (1%)]\tLoss: 0.005591\n",
      "Train Epoch: 33 [2000/3000 (67%)]\tLoss: 0.006023\n",
      "Train Epoch: 33 [2980/3000 (100%)]\tLoss: 0.006068\n",
      "\n",
      "Test set: Average loss for  model: 0.6067, Accuracy: 694/753 (92%)\n",
      "\n",
      "Train Epoch: 34 [0/3000 (1%)]\tLoss: 0.006051\n",
      "Train Epoch: 34 [2000/3000 (67%)]\tLoss: 0.006016\n",
      "Train Epoch: 34 [2980/3000 (100%)]\tLoss: 0.006014\n",
      "\n",
      "Test set: Average loss for  model: 0.5901, Accuracy: 703/753 (93%)\n",
      "\n",
      "Train Epoch: 35 [0/3000 (1%)]\tLoss: 0.006883\n",
      "Train Epoch: 35 [2000/3000 (67%)]\tLoss: 0.006515\n",
      "Train Epoch: 35 [2980/3000 (100%)]\tLoss: 0.006014\n",
      "\n",
      "Test set: Average loss for  model: 0.6039, Accuracy: 691/753 (92%)\n",
      "\n",
      "Train Epoch: 36 [0/3000 (1%)]\tLoss: 0.006514\n",
      "Train Epoch: 36 [2000/3000 (67%)]\tLoss: 0.005640\n",
      "Train Epoch: 36 [2980/3000 (100%)]\tLoss: 0.006476\n",
      "\n",
      "Test set: Average loss for  model: 0.6004, Accuracy: 695/753 (92%)\n",
      "\n",
      "Train Epoch: 37 [0/3000 (1%)]\tLoss: 0.006015\n",
      "Train Epoch: 37 [2000/3000 (67%)]\tLoss: 0.005521\n",
      "Train Epoch: 37 [2980/3000 (100%)]\tLoss: 0.006015\n",
      "\n",
      "Test set: Average loss for  model: 0.5896, Accuracy: 701/753 (93%)\n",
      "\n",
      "Train Epoch: 38 [0/3000 (1%)]\tLoss: 0.005966\n",
      "Train Epoch: 38 [2000/3000 (67%)]\tLoss: 0.005515\n",
      "Train Epoch: 38 [2980/3000 (100%)]\tLoss: 0.005514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss for  model: 0.6047, Accuracy: 691/753 (92%)\n",
      "\n",
      "Train Epoch: 39 [0/3000 (1%)]\tLoss: 0.005515\n",
      "Train Epoch: 39 [2000/3000 (67%)]\tLoss: 0.005515\n",
      "Train Epoch: 39 [2980/3000 (100%)]\tLoss: 0.005982\n",
      "\n",
      "Test set: Average loss for  model: 0.6029, Accuracy: 691/753 (92%)\n",
      "\n",
      "Train Epoch: 40 [0/3000 (1%)]\tLoss: 0.006035\n",
      "Train Epoch: 40 [2000/3000 (67%)]\tLoss: 0.005942\n",
      "Train Epoch: 40 [2980/3000 (100%)]\tLoss: 0.006228\n",
      "\n",
      "Test set: Average loss for  model: 0.5886, Accuracy: 706/753 (94%)\n",
      "\n",
      "Train Epoch: 41 [0/3000 (1%)]\tLoss: 0.006032\n",
      "Train Epoch: 41 [2000/3000 (67%)]\tLoss: 0.005820\n",
      "Train Epoch: 41 [2980/3000 (100%)]\tLoss: 0.006512\n",
      "\n",
      "Test set: Average loss for  model: 0.5965, Accuracy: 697/753 (93%)\n",
      "\n",
      "Train Epoch: 42 [0/3000 (1%)]\tLoss: 0.005515\n",
      "Train Epoch: 42 [2000/3000 (67%)]\tLoss: 0.006118\n",
      "Train Epoch: 42 [2980/3000 (100%)]\tLoss: 0.005514\n",
      "\n",
      "Test set: Average loss for  model: 0.5950, Accuracy: 699/753 (93%)\n",
      "\n",
      "Train Epoch: 43 [0/3000 (1%)]\tLoss: 0.006110\n",
      "Train Epoch: 43 [2000/3000 (67%)]\tLoss: 0.005515\n",
      "Train Epoch: 43 [2980/3000 (100%)]\tLoss: 0.005924\n",
      "\n",
      "Test set: Average loss for  model: 0.5905, Accuracy: 703/753 (93%)\n",
      "\n",
      "Train Epoch: 44 [0/3000 (1%)]\tLoss: 0.005514\n",
      "Train Epoch: 44 [2000/3000 (67%)]\tLoss: 0.005682\n",
      "Train Epoch: 44 [2980/3000 (100%)]\tLoss: 0.005839\n",
      "\n",
      "Test set: Average loss for  model: 0.5992, Accuracy: 695/753 (92%)\n",
      "\n",
      "Train Epoch: 45 [0/3000 (1%)]\tLoss: 0.005520\n",
      "Train Epoch: 45 [2000/3000 (67%)]\tLoss: 0.005917\n",
      "Train Epoch: 45 [2980/3000 (100%)]\tLoss: 0.005516\n",
      "\n",
      "Test set: Average loss for  model: 0.5845, Accuracy: 708/753 (94%)\n",
      "\n",
      "Train Epoch: 46 [0/3000 (1%)]\tLoss: 0.005517\n",
      "Train Epoch: 46 [2000/3000 (67%)]\tLoss: 0.005541\n",
      "Train Epoch: 46 [2980/3000 (100%)]\tLoss: 0.005514\n",
      "\n",
      "Test set: Average loss for  model: 0.6057, Accuracy: 689/753 (92%)\n",
      "\n",
      "Train Epoch: 47 [0/3000 (1%)]\tLoss: 0.006021\n",
      "Train Epoch: 47 [2000/3000 (67%)]\tLoss: 0.005515\n",
      "Train Epoch: 47 [2980/3000 (100%)]\tLoss: 0.005519\n",
      "\n",
      "Test set: Average loss for  model: 0.5901, Accuracy: 704/753 (93%)\n",
      "\n",
      "Train Epoch: 48 [0/3000 (1%)]\tLoss: 0.005515\n",
      "Train Epoch: 48 [2000/3000 (67%)]\tLoss: 0.006131\n",
      "Train Epoch: 48 [2980/3000 (100%)]\tLoss: 0.005801\n",
      "\n",
      "Test set: Average loss for  model: 0.5975, Accuracy: 699/753 (93%)\n",
      "\n",
      "Train Epoch: 49 [0/3000 (1%)]\tLoss: 0.006015\n",
      "Train Epoch: 49 [2000/3000 (67%)]\tLoss: 0.005596\n",
      "Train Epoch: 49 [2980/3000 (100%)]\tLoss: 0.005514\n",
      "\n",
      "Test set: Average loss for  model: 0.5972, Accuracy: 698/753 (93%)\n",
      "\n",
      "Train Epoch: 50 [0/3000 (1%)]\tLoss: 0.005514\n",
      "Train Epoch: 50 [2000/3000 (67%)]\tLoss: 0.005514\n",
      "Train Epoch: 50 [2980/3000 (100%)]\tLoss: 0.005518\n",
      "\n",
      "Test set: Average loss for  model: 0.5911, Accuracy: 701/753 (93%)\n",
      "\n",
      "Train Epoch: 51 [0/3000 (1%)]\tLoss: 0.005530\n",
      "Train Epoch: 51 [2000/3000 (67%)]\tLoss: 0.005796\n",
      "Train Epoch: 51 [2980/3000 (100%)]\tLoss: 0.006014\n",
      "\n",
      "Test set: Average loss for  model: 0.5965, Accuracy: 696/753 (92%)\n",
      "\n",
      "Train Epoch: 52 [0/3000 (1%)]\tLoss: 0.006014\n",
      "Train Epoch: 52 [2000/3000 (67%)]\tLoss: 0.005585\n",
      "Train Epoch: 52 [2980/3000 (100%)]\tLoss: 0.005515\n",
      "\n",
      "Test set: Average loss for  model: 0.6013, Accuracy: 694/753 (92%)\n",
      "\n",
      "Train Epoch: 53 [0/3000 (1%)]\tLoss: 0.005517\n",
      "Train Epoch: 53 [2000/3000 (67%)]\tLoss: 0.006023\n",
      "Train Epoch: 53 [2980/3000 (100%)]\tLoss: 0.005515\n",
      "\n",
      "Test set: Average loss for  model: 0.5945, Accuracy: 700/753 (93%)\n",
      "\n",
      "Train Epoch: 54 [0/3000 (1%)]\tLoss: 0.005514\n",
      "Train Epoch: 54 [2000/3000 (67%)]\tLoss: 0.005516\n",
      "Train Epoch: 54 [2980/3000 (100%)]\tLoss: 0.005525\n"
     ]
    }
   ],
   "source": [
    "train(args, device, model, optimizer, criterion, global_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e8dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
