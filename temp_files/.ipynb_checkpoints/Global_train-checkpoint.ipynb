{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c766609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8080769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.images = 3012\n",
    "        self.epochs = 100\n",
    "        self.clients = 1\n",
    "        self.local_batches = 20\n",
    "        self.lr = 0.01\n",
    "        self.iid = 'iid'\n",
    "        self.dropout1 = 0.25\n",
    "        self.dropout2 = 0.5\n",
    "        self.drop_rate = 0.1\n",
    "        self.torch_seed = 0\n",
    "        self.log_interval = 100\n",
    "        self.use_cuda = True\n",
    "        self.save_model = False\n",
    "        self.save_model_interval = 200\n",
    "        self.clip = 1\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = args.use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0126ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovidDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.data_info = pd.read_csv(csv_path, header=None)\n",
    "        self.transform = transform\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.data_info.iloc[idx, 0]\n",
    "        image = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)\n",
    "        label = self.data_info.iloc[idx, 1]\n",
    "        label = np.array([label])\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        img = cv2.resize(image, (self.output_size, self.output_size))\n",
    "\n",
    "        return {'image': img, 'label': label}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "#         print(\"image type: \", type(image))\n",
    "#         print(\"image shape: \", image.shape)\n",
    "        tensor_img = torch.from_numpy(image)\n",
    "        tensor_img = tensor_img.unsqueeze(dim=0)\n",
    "        tensor_img = tensor_img.type('torch.FloatTensor')\n",
    "        tensor_lb = torch.from_numpy(label)\n",
    "#         print(\"tensor_img shape: \", tensor_img.shape)\n",
    "#         print(\"tensor_lb shape: \", tensor_lb.shape)\n",
    "#         print(\"tensor_img type: \", type(tensor_img))\n",
    "        return {'image': tensor_img,\n",
    "                'label': tensor_lb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3da7566",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train_dataset = CovidDataset('./train.csv', transform=transforms.Compose([Rescale(32), ToTensor()]))\n",
    "global_train_loader = DataLoader(global_train_dataset, batch_size=args.local_batches, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c9ae682",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_test_dataset = CovidDataset('./test.csv', transform=transforms.Compose([Rescale(32), ToTensor()]))\n",
    "global_test_loader = DataLoader(global_test_dataset, batch_size=args.local_batches, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c992580",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1,\n",
    "                               out_channels = 32,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32,\n",
    "                               out_channels = 64,\n",
    "                               kernel_size = 3,\n",
    "                               stride = 1)\n",
    "        self.fc1 = nn.Linear(14*14*64, 128)\n",
    "        self.fc1_bn = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "#         x = self.conv1_bn(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.dropout(x, p=args.dropout1)\n",
    "        x = x.view(-1, 14*14*64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=args.dropout2)\n",
    "#         x = self.fc1_bn(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143e9468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, device, model, optimizer, criterion, train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            data = batch['image']\n",
    "            target = batch['label']\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.squeeze(1))\n",
    "            loss.backward()\n",
    "    \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % args.log_interval == 0 or batch_idx==len(train_loader)-1:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, \n",
    "                    batch_idx * args.local_batches, \n",
    "                    len(train_loader) * args.local_batches, \n",
    "                    100. * (batch_idx+1) / len(train_loader), \n",
    "                    loss.item()/args.log_interval))\n",
    "                \n",
    "        acc = test(args, model, device, global_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55fa3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()   \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for d in test_loader:\n",
    "            data = d['image']\n",
    "            target = d['label']\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if(str(device)=='cuda'):\n",
    "                model.cuda()\n",
    "            output = model(data.float())\n",
    "#             test_loss += F.nll_loss(output, target.squeeze(1), reduction='sum').item() # sum up batch loss\n",
    "            loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "            test_loss += loss_fn(output, target.squeeze(1)).item() # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss for  model: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895f7222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n",
      "  (fc1_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum = 0.8)\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84a0187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(global_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeac66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/citi302/anaconda3/envs/FLcourse/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3000 (1%)]\tLoss: 0.010502\n",
      "Train Epoch: 0 [2000/3000 (67%)]\tLoss: 0.013014\n",
      "Train Epoch: 0 [2980/3000 (100%)]\tLoss: 0.011514\n",
      "\n",
      "Test set: Average loss for  model: 1.1953, Accuracy: 248/753 (33%)\n",
      "\n",
      "Train Epoch: 1 [0/3000 (1%)]\tLoss: 0.013014\n",
      "Train Epoch: 1 [2000/3000 (67%)]\tLoss: 0.013514\n",
      "Train Epoch: 1 [2980/3000 (100%)]\tLoss: 0.012514\n",
      "\n",
      "Test set: Average loss for  model: 1.1966, Accuracy: 247/753 (33%)\n",
      "\n",
      "Train Epoch: 2 [0/3000 (1%)]\tLoss: 0.012014\n",
      "Train Epoch: 2 [2000/3000 (67%)]\tLoss: 0.012514\n",
      "Train Epoch: 2 [2980/3000 (100%)]\tLoss: 0.011514\n",
      "\n",
      "Test set: Average loss for  model: 1.1980, Accuracy: 246/753 (33%)\n",
      "\n",
      "Train Epoch: 3 [0/3000 (1%)]\tLoss: 0.012014\n",
      "Train Epoch: 3 [2000/3000 (67%)]\tLoss: 0.011514\n",
      "Train Epoch: 3 [2980/3000 (100%)]\tLoss: 0.011014\n",
      "\n",
      "Test set: Average loss for  model: 1.1953, Accuracy: 248/753 (33%)\n",
      "\n",
      "Train Epoch: 4 [0/3000 (1%)]\tLoss: 0.012014\n",
      "Train Epoch: 4 [2000/3000 (67%)]\tLoss: 0.013014\n",
      "Train Epoch: 4 [2980/3000 (100%)]\tLoss: 0.012514\n",
      "\n",
      "Test set: Average loss for  model: 1.1953, Accuracy: 248/753 (33%)\n",
      "\n",
      "Train Epoch: 5 [0/3000 (1%)]\tLoss: 0.011014\n",
      "Train Epoch: 5 [2000/3000 (67%)]\tLoss: 0.013014\n",
      "Train Epoch: 5 [2980/3000 (100%)]\tLoss: 0.011014\n",
      "\n",
      "Test set: Average loss for  model: 1.1927, Accuracy: 250/753 (33%)\n",
      "\n",
      "Train Epoch: 6 [0/3000 (1%)]\tLoss: 0.013014\n",
      "Train Epoch: 6 [2000/3000 (67%)]\tLoss: 0.014514\n",
      "Train Epoch: 6 [2980/3000 (100%)]\tLoss: 0.011514\n",
      "\n",
      "Test set: Average loss for  model: 1.1993, Accuracy: 245/753 (33%)\n",
      "\n",
      "Train Epoch: 7 [0/3000 (1%)]\tLoss: 0.011514\n",
      "Train Epoch: 7 [2000/3000 (67%)]\tLoss: 0.013514\n",
      "Train Epoch: 7 [2980/3000 (100%)]\tLoss: 0.013514\n",
      "\n",
      "Test set: Average loss for  model: 1.1993, Accuracy: 245/753 (33%)\n",
      "\n",
      "Train Epoch: 8 [0/3000 (1%)]\tLoss: 0.013514\n",
      "Train Epoch: 8 [2000/3000 (67%)]\tLoss: 0.010014\n",
      "Train Epoch: 8 [2980/3000 (100%)]\tLoss: 0.012014\n",
      "\n",
      "Test set: Average loss for  model: 1.1993, Accuracy: 245/753 (33%)\n",
      "\n",
      "Train Epoch: 9 [0/3000 (1%)]\tLoss: 0.012014\n",
      "Train Epoch: 9 [2000/3000 (67%)]\tLoss: 0.013014\n",
      "Train Epoch: 9 [2980/3000 (100%)]\tLoss: 0.013014\n",
      "\n",
      "Test set: Average loss for  model: 1.1966, Accuracy: 247/753 (33%)\n",
      "\n",
      "Train Epoch: 10 [0/3000 (1%)]\tLoss: 0.012514\n"
     ]
    }
   ],
   "source": [
    "train(args, device, model, optimizer, criterion, global_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cd99d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
